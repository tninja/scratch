#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:nil arch:headline
#+OPTIONS: author:t broken-links:nil c:nil creator:nil
#+OPTIONS: d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t num:t
#+OPTIONS: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+OPTIONS: timestamp:t title:t toc:nil todo:t |:t
#+TITLE: 谦卑的程序员
#+DATE: <2020-07-04 Sat>
#+AUTHOR: Edsger W. Dijkstra
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 26.3 (Org mode 9.1.9)

* 中文版

** 上
   
[[./images/dijkstra.1.jpg]]

机缘巧合，1952 年春的第一个早晨，我正式进入了软件编程行业。据我所知，我是荷兰的第一个程序员。回想起来，最令人惊讶的，是编程行业发展的速度之慢，至少在我的那部分世界里，这简直令人难以置信。但是我的内心对那个时期的两段生动回忆充满感激之情，但这两段回忆也不容置疑地证实了软件行业缓慢发展的状态。
 
在经历了三年的编程之后，我与 A. van Wijngaarden 有过一次讨论，他当时是我在阿姆斯特丹数学中心的老板。这次讨论，让我觉得只要我依稀尚存，就会一直对他心存感激。那时，我本应该在学习编程的同时去莱顿大学学习理论物理，但我逐渐发现这两个科目越来越难结合到一起。因此我不得不做出决定，要么放弃编程，成为一名真正受人尊敬的理论物理学家，要么继续我的物理学习，用最少的努力正式完成学业，然后变成……是的，变成什么？一名程序员？但那是一个受人尊敬的职业吗？回到问题本源来看，编程究竟是什么？可以使编程成为一项高智力的、受人尊敬的学科的健全知识体系在哪里？我非常清晰地记得，我是多么嫉妒我那些搞硬件的同事。当被问及他们的职业竞争力时，他们至少能够说出，他们知道真空管、放大器和其他相关的硬件知识。但我觉得，当我面对这样的问题时，我只能两手空空地站在那里。我满怀疑虑地敲响了 van Wijngaarden 的办公室门，问他是否可以和他说上一会儿话。几个小时后，我离开了他的办公室，变成了另外一个人。因为，在耐心地听取了我的问题之后，他同意我的说法，此时此刻还没有计算机编程这门学科，但他继续静静地解释道，自动计算机就在这儿，我们才刚刚起步，而在未来几年，我能不能成为那个人呢？那个让编程变为一项值得尊敬的职业的人？这段对话成了我生命中的转折点。我尽可能快地正式完成了物理学业。这段经历也带来一个道德上的启示：当我们给年轻人提出建议的时候，我们必须非常慎重，因为有时候他们真的会照着你说的去做。
 
两年之后，也就是 1957 年，我结婚了。在荷兰的婚礼仪式上，需要你说说自己的职业。我说，我是一位程序员。但是，阿姆斯特丹市政当局不接受，理由是没有这样的职业。不管你信不信，在我的婚姻证上，职业这一栏下面居然荒谬地写着“理论物理学家”。
 
这就是在我自己的国家，编程行业发展如此之慢的原因。自那以后，我看到了更广阔的世界。在我的总体印象里，其他的国家也有着非常一致的增长模式，除了日期上可能有些差异罢了。
 
为了能对当前情况作出更好的理解，请允许我更详细地介绍一下。在我们进行分析时，各位将看到我们对编程的本质产生了多少常识性的误解，而这些误解可以追溯到很久之前。
 
第一批自动电子计算机是独一无二的单拷贝机器，它们是在当时研究热情高涨的实验室环境中被发明出来的。就当时的电子技术而言，发明这样的自动电子计算机是一项巨大的挑战。但有一点可以肯定：我们不能否认那些决定尝试打造如此出色设备的团队成员们的勇气。对于那些梦幻般的设备，人们回想起来不禁惊讶，它们竟然可以运转，至少有时可以。当时的一个大问题是如何让机器保持有序的运转。在该领域中较老的科学协会的名称中，仍然反映出对自动计算的物理方面的关注，例如计算机械协会或英国计算机协会这样的名称，其中明确提到了物理设备。
 
那可怜的程序员怎么办？好吧，老实说：人们几乎很难注意到他们。首先，第一批机器太庞大了，以至于你很难移动他们。除此之外，他们需要大量的维修，所以使用它们的地点，自然也就在发明这批机器的实验室里了。其次，程序员的软件编程工作成果不是可见的实物，这看起来没有任何吸引力：你可以向来访者展示这些可见的机器，这比几段代码要壮观几个数量级。更为重要的是，这些程序员对自己的工作也非常谦虚：他们认为这份工作正因这台绝妙的机器而体现出价值。由于这是一台独一无二的机器，他们非常清楚编出来的程序只能用在这台机器上，而且显然，这台机器的生命周期有限，他们很难知道现在的编程工作是否具有持久的价值。最后，还有另外一种情况对程序员的工作态度产生了深远的影响：一方面，除了机器不可靠，这台机器运行还很慢，内存也很小，这就像面对着一只夹脚的小鞋一样；另一方面，用这台机器写出来的或多或少有些怪异的代码，会产生非预期的的程序构建过程。在那个年代，许多聪明的程序员运用了很多编程技巧，才使代码符合了这台机器的诸多限制，不过这也让程序员们获得了巨大的智力上的满足感。
 
在那个编程时代有两种观点。我现在先提一下这些观点，稍后还会再提到它们。一个观点是说，一个具有真正竞争力的程序员，应该是喜欢思考疑难问题的，并且喜欢研究一些精妙的编程技巧；另外一个观点是，编程无非是从不同的方向来优化计算过程的效率。
 
之所以出现后面这个观点，是因为现有的这台设备就像一只夹脚的鞋子一样让人难受，所以在那个年代人们甚至产生了这样天真的期望，即一旦强大的机器出现了，编程将不再是问题，到那时，一切将现有这台机器的计算资源利用率推向极致的努力都不再是必要的，这不就是编程的所有意义吗？但是在接下来的几十年里，发生了一些事情，它们和后面这个观点完全不同：更加强大的机器确实出现了，不止是强大了一个数量级，而是强大了几个数量级，但是我们并没有解决编程上的所有问题，相反的，我们发现自己陷入了软件危机的困境中。这是怎么回事呢？
 
我们先来看一个次要原因：从某些方面来看，现代机器基本上比旧的机器更难使用。首先，新机器有 I/O 中断，他们的出现时机是不可预测的，并且不好重现。相比序列化运行的旧机器，其自动化过程被假定为是一个完全确定的过程。这是一个巨大的变化，许多系统程序员的苍苍白发见证了这个事实，那就是我们不应该只是草草地讨论该功能所引发的逻辑问题。其次，我们有了装配多级存储的机器，这样就给我们带来了管理策略的问题，尽管围绕这一方面的讨论有很多的文献，但这仍然是一个难以捉摸的问题。以上这些就是由机器结构变化而引入的复杂性。
 
以上这些，我只是称其为次要原因，那主要原因……就是现代机器已经比以前的机器强大了好几个数量级！直截了当地讲，没有机器的年代，我们不会想到用编程去解决问题，而当我们有一些能力很弱的机器时，编程也只能解决一些很小的问题。但现在我们有了更强大的计算机，编程也就水涨船高地需要解决更大的问题。从这个意义上讲，电子工业，从来没有解决任何一个问题，相反，它在使用它自己生产的产品制造问题。换句话说，当已有机器的性能增长了 1000 倍的时候，社区想利用这些机器来解决问题的雄心壮志也会得到成正比的增长。在这个爆炸式增长的领域，可怜的程序员们发现他们在目的和方式之间徘徊游走。增强的硬件性能及可靠性（相比性能而言，可靠性增强的幅度可能更大），使得程序员们几年前不敢想像的解决方案变得切实可行。所以在几年之后，程序员们不得不开始思考这些方案。更糟糕的是，他们不得不将以前的这些梦想变成现实！我们发现自己陷入了软件危机，这个现象会令人费解吗？不，当然不，正如你可能猜到的那样，它甚至是可以提前预测的；但是让小先知伤脑筋的是，你得在 5 年之后才能知道他们的预测是正确的。
 
后来，到了 60 年代中期，可怕的事情发生了：所谓的第三代计算机出现了。官方文献告诉我们，这些机器的性价比成为了主要的设计目标之一。但是如果你把机器不同组件的工作周期作为性能衡量因素，那你很可能得到这样一个设计：通过机器内部组件间的管理优化，来达到你的主要性能目标，为了达成性能目标而采用这个方式的必要性却值得怀疑。如果你对价格的定义是要付给硬件的价格的话，那你很可能做出一个硬件设计，这个设计将很难用于编程：例如不管依赖程序员还是系统的指令码，可能会执行早期绑定决策，这些决策可能会产生无法解决的冲突。而且从很大程度上来讲，这些令人不愉快的可能性，看起来正在变成现实。

当这些机器被公布出来，并且他们的规格为人所知之后，我们当中的很多人一定会变得非常悲惨，至少我就是。这些机器可能会充斥整个计算社区。所以这里重要的是，他们的设计应当是非常健全的。但实际上这样的设计有着非常严重的缺陷，这让我觉得，这些机器随便一次出错，计算科学的进展将会被延迟至少 10 年：也正是那时，我度过了职业生涯中最黑暗的一个星期。也许现在最悲哀的事情是，在经历了这些年这么多令人沮丧的经历后，仍然有这么多人仿佛受到某种自然法则的指引，他们真诚地相信，机器就应该是这样设计的。他们对质疑保持了沉默，因为他们看到许多人都在购买这些机器。通过观察，他们得到了一些对安全性的错误认识，毕竟有这么多人买它，那它的设计应该不会很糟糕。但是我们好好想想，基于这个逻辑，是不是可以说吸烟一定有益健康呢，因为有这么多人都在吸烟。
 
计算领域的科学杂志，还不习惯像审查科学出版物一样，审查最新发明的计算机，但是至少应当把审查机器作为同等重要的事情。对于这一点我表示很遗憾。在这里我需要坦白一下，在 60 年代早期，我写了一篇评论，目的是想提交给 CACM 的审稿人。我把这篇评论发给了我的几位同事，以征求他们的意见，尽管他们催促我，让我赶紧提交到 CACM，但是我并不敢做这样的事情，因为我害怕给我自己或编辑部的人带来太多的困难。对我来说，这种压抑是一种懦弱的行为，我因此不断责备自己。我预见到的困难是当时缺少一些普遍被接受的关于机器审查的标准，尽管我认为我所选择的一些标准是合理的，但是我仍然害怕我的评论会被拒绝，或者被认为仅仅是我自己的个人喜好而被抛弃。我现在仍然认为这样的审查将是非常有用的，并且我期待看到它们的出现，因为它们的出现，预示着计算社区走向成熟。

我之所以关注硬件场景，是因为我觉得任何计算工具最重要的一个方面，就是它对试图使用它的人在思维习惯上产生的影响，而且我有理由相信，这种影响比通常假设的要高很多倍。现在让我们转到软件场景上来。

软件场景中的多样性是如此之大，我必须得将此场景限制在少数几个软件领域的奠基石上。我痛苦地意识到我的选择如此随机武断，有太多的推进软件进程的贡献未曾提及和赞扬，请大家谅解。

首先是英国剑桥的 EDSAC ，我认为它非常令人印象深刻，因为从一开始，在这个机器的设计以及使用中，子程序库的概念就扮演了一个核心角色。25 年过去了，计算场景发生了巨大的变化，但是基本的软件概念仍然伴随着我们，封闭式子程序的概念仍然是编程中的关键概念之一。我们应当把封闭式子程序看作是最伟大的软件发明之一。它历经了三代计算机，而且应该会持续更长的时间，因为它迎合了人类最基本的抽象模式。但是遗憾的是，封闭式子程序的重要性在第三代计算机的设计中被低估了，在第三代计算机中，大量显示命名的算术单元寄存器，暗示着子程序机制的开销会很大。但即使那样也没有消灭子程序这个概念，我们只能祈祷，第三代计算机的这种突变不会遗传下去。

软件场景中第二个我想提到的的主要发展是 FORTRAN 语言的诞生。在那个年代，这是一个极具冒险精神的项目，而负责此项目的人应当受到极大的尊敬。它存在一些缺点，但如果因此去责备它，那将是不公平的，因为在广泛使用了数十年之后，它的缺点才显现出来：能够预测 10 年的团队，那都是非常罕见的！回顾往事， FORTRAN 作为一项编码技术是成功的，但它缺少有效的辅助工具来帮助人们理解其代码，这样的工具正是我们现在急需的，而在那个时候，他们认为这样的工具是落后的。我们能够越快地忘掉 FORTRAN，那就会越好，因为作为一个思想的载体，它已经不再适合我们：它浪费我们的脑力，并且风险太大，所以用起来会很昂贵。FORTRAN 的悲哀，正是因为它被广泛地接受和使用，而其历代版本产生的兼容性问题，使得成千上万的程序员感到困扰。我每天都祈祷，希望我越来越多的程序员伙伴们可以找到从兼容性诅咒中解脱出来的办法。

第三个我想提到的项目是 LISP，这个项目具有完全不同的绝妙特点。其底层仅有少数几个最基本的原则，因此它展示了极强的稳定性。除此之外，最复杂的计算机应用程序中，有相当一部分都使用了 LISP。 LISP 被开玩笑似地描述为“滥用一台计算机最聪明的方式”。我认为这样的描述是极大的赞美，因为它传达了解放的全部含义：它能帮助我们一些最有天赋的程序员思考以前所不能思考的问题。

第四个要提到的项目是 ALGOL 60。FORTRAN 程序员仍然倾向于就他们正在致力于具体实现的方面去理解他们的编程语言，因此八进制和十六进制转储变得普遍起来；而 LISP 语言的定义仍然是一个奇怪的组合，即该语言的含义和其工作原理的组合。相比而言，关于算法语言 ALGOL 60 的那份著名报告是一项不懈努力的成果，它在语言抽象上迈出了关键的一步，并以独立于实现的方式定义了一种编程语言。可能有些人会争辩说，在这个方面它的作者已经非常成功了，以至于他们怀疑这个语言究竟是否能被实现出来！这篇报告非常精彩地展示了 BNF 方法的力量，该方法现在被称做 Backus-Naur-Form（巴科斯 - 诺尔范式）；同时他也非常精彩地展示了精心分词的英语的力量，特别是连 Peter Naur 这样出色的人都在使用它。我觉得这样说是很公平的：即很少有文档能如此短小，却对计算社区有着同样深远的影响。在后面的几年里，ALGOL 和 ALGOL-like 这样的名字被轻易地用作不受保护的商标，这为一些几乎不相关的新项目带来了好处。相对于该语言的地位来说，这多多少少有点令人震惊。作为设备定义语言，BNF 的优势反倒突显了 ALGOL 60 语言的缺陷，这门语言的过度复杂性，以及不那么系统化的语法，应该可以仅用少量几页文档描述清楚。有了像 BNF 这样强大的方法，ALGOL 60 算法语言报告本应变得更短。除此之外，我非常怀疑 ALGOL 60 的参数机制：他允许程序员有如此多的组合自由，这要求程序员们具有强大的自律性。除了实现起来很昂贵，用起来似乎也比较危险。

最后，虽然这不是一个愉快的主题，但我必须要提到 PL/1，这是一种编程语言，其文档的大小和复杂性令人恐惧。使用 PL/1 必须像驾驶一架飞机一样，在驾驶舱中操纵 7000 个按钮、开关和手柄。我绝对看不出我们是怎样把不断增长的程序，牢牢地把握在我们自己的智力控制之中，因为它使用纯粹的巴洛克式的编程语言。我需要提醒一下，作为我们最基本的工具，它都有这么复杂，已经超出了我们的智力控制。如果我不得不描述 PL/1 在它的使用者身上的影响的话，我能想到最接近的比喻就是毒品。我记得在一个关于高级程序设计语言的专题讨论会上，一个男人称他是这门语言的忠实用户，在他一个小时的演讲中，他不断地赞扬 PL/1，同时他设法要求额外增加 50 个新功能，而他几乎没有意识到，他的问题来源可能正是因为这门语言已经包含了太多的功能。这位演讲者所说添加额外功能的要求令人沮丧，而演讲者本人则处于不断要求添加更多、更多功能的精神停滞和麻木状态。当 FORTRAN 语言被称为处于婴儿紊乱状态阶段时，PL/1 就像是一个肿瘤在不断地增长，它可能会癌变。

俱往矣，除非我们能够从错误中学到经验教训，否则没有必要再犯像之前一样的错误。事实上，我认为我们已经学到了很多，以至于在几年之内，编程可能会成为一项和以往完全不同的活动，我们最好为之做充分的准备。让我为你描绘一个可能的未来。乍一看，在不久的将来，这种编程愿景可能会让你觉得非常棒。因此，人们也许会得出结论，说这样的愿景，可能很好实现。

这个愿景就是，在 70 年代结束之前，我们将能够设计和实现一种系统，这种系统可以充分利用我们现在的编程能力，其成本只有我们现在人力的百分之几。除此以外，这些系统几乎没有任何 bug。这两项改进是相辅相成的。在后者方面，软件产品似乎不同于很多其他的产品，这些产品的质量越高，价格也就越高。而如果想要得到真正可靠的软件，就必须找到一种避免大部分 bug 的方式，在这种方式下，编程过程将变得更加便宜。如果你想得到更有效率的程序员，你会发现，他们不会在调试程序上浪费时间，他们一开始就不会引入 bug。换句话说，上述两个目标都指向了同样的改变。

如此短暂的时间内，进行如此剧烈的变化将是一场革命。对所有人来说，都是基于他们的经验。从最近的历史平缓地推测未来，一些不成文的社会法则和文化惯性起到了强大的作用，这意味着发生剧变的概率似乎可以忽略不计。但是我们知道，有时候变革确实会发生，那这次变革发生的几率有多大呢？

** 下

[[./images/dijkstra.2.jpg]]

变革的发生看起来需要满足三个主要条件：

    首先，整个世界必须认识到改变的必要性；
    其次，来自经济上的诉求必须足够强烈；
    第三，这个改变必须是技术上可行的。

就让我按照这个顺序来讨论这三个条件。

    对于需要认识到软件的可靠性需求

我猜业界目前在这方面是没有任何分歧的。而就在几年前，情况都很不相同：那时谈论软件危机是亵渎神明的。转折点是 1968 年 10 月在 Garmisch 举办的软件工程会议。这次会议上，软件危机被首次公开承认，这引起了不小的轰动。到目前为止，人们普遍认为，任何大型复杂系统的设计，都将是一项困难的工作，每当遇到负责此类工作的人员时，人们都会发现，他们非常关注软件可靠性，这是正确的。简而言之，我们的第一个条件看起来是满足的。

    现在来看一下经济诉求

如今人们经常会遇到这样的观点，在 60 年代，软件编程是一个薪水过高的职业，而且在接下来的几年里，程序员的薪水可能会被下调。通常这样的观点与经济衰退有关，但它可能是在表达一些不同但却十分有益的观点：也许过去十几年，程序员没有做好他们本应该做好的工作。社会对程序员的表现及其产品非常不满意。但还有另一个更重要的因素，目前，对于一个特定的系统，软件开发所付的薪水和当时的硬件价格处于同一个数量级，而人们或多或少认同这一点。但是硬件制造商告诉我们，在接下来的十几年中，硬件价格可能会降低一个数量级。但如果软件开发，仍然像现在这样笨拙而且昂贵，那么事情就会完全失去平衡。你不会期望社会接受这个现象的，于是我们必须学习如何将编程效率提高一个数量级。换句话说，只要机器是预算中最大的一项，那软件编程这个职业，就不存在技术笨拙的问题，但由于硬件价格下降非常快，所以这把经济上的保护伞也将会收拢得非常快。简而言之，我们的第二项条件看起来也是满足的。

    现在到了第三个条件，它是技术可行的吗？

我想应该是的，我会给你六个论据来支持这个观点。

关于计算机程序结构的一项研究揭示出，有些程序即使是为执行同一任务而编写，即使用到相同的数学算法，他们在可管理性上也会有巨大的不同。人们发现了大量的规则，一旦违反这些规则，程序的可管理性将受到极大程度的损坏甚至被完全摧毁。这些规则分为两类。第一类可以很好地从机制上进行保证，即适当地选择编程语言，例如不要使用 goto 语句，也不要在函数里返回多个输出参数。对于第二类，至少我没有看见机制上的保证（也许是我所知有限），因为似乎需要某种自动的理论证明才能看到违反这类规则的后果，而我现在还没有这样的证明。因此不管现在还是将来，程序员都需要通过自我约束来遵守第二类规则。这其中的某些规则是如此显而易见，以至于程序员们可以通过学习来掌握，并且在讨论某程序是否违反了这些规则时，永远也不会产生争议，例如，程序中的循环结构如果不具备终止条件，或者反复执行循环中的语句会破坏程序的稳定性，程序员们是不会写下这样的循环代码的。

我建议我们仅设计和实现理解性优良的程序。如果某些人害怕这个限制太严格，那我可以向他保证：想要得到任何现实问题的算法解决方案，这类理解性优良的程序足以。我们必须记得，我们的职责不是制造程序，我们的职责是设计能得到预期行为的程序。而以上建议，将是我要阐述的六个观点中前两个的基础。

    论据一，由于程序员们只考虑理解性优良的这些程序，那他们在这个范畴中再选择不同方案时，将会变得很容易。

    论据二，一旦我们决定，只在理解性优良的程序中进行选择，那我们就可以很大程度地缩小候选方案数量。注意这个观点和第一个观点有所不同。

    论据三，是基于程序正确性的一套建设性方法。目前编程常用的一个方式是先写一个程序，然后测试它。虽然程序测试是找到 bug 的一个非常有效的方法，但这种方法却不能证明，程序中没有 bug。为了让人们更加相信程序是正确的，唯一的方法就是给出一个有说服力的证明。但程序员们不应该先写程序，然后再证明它的正确性，因为这样会增加程序员们的负担。相反的，程序员应该一边证明正确性，一边写程序。本观点基于如下的观察：程序员如果先问自己，有说服力的证明具有什么样的结构，找到它，然后构建一个满足这个证明需求的程序，那么，关于证明正确性的这些考量，就会成为一个非常有启发，非常有效的编程指引。通过以上观察可知，只有在考虑理解性好的程序时，这个方法才适用，但是它提供了一种有效的手段，帮助我们找到这样的程序。

    论据四，是关于某种途径的。通过这种途径，设计程序所需的脑力活动量依赖于程序的长度。据说，某种自然法则告诉我们，脑力活动量会随着程序长度的平方而增加。但是，谢天谢地，没有人能够证明这一点，这可能是因为这个说法本身是不对的。我们都知道，把有限的推理过程覆盖到大量的具体情况上，这样的思维方式叫做“抽象“。所以对于抽象能力的有效挖掘，应当是一名合格程序员所从事的最关键的事项之一。说到这里，应该指出的是，抽象的目的不是为了让事情看起来更模糊，而是在一个新的语义层面让人们看到更精确的东西。当然，我也曾经尝试过寻找更基本的触发因素，好让我们的“抽象”机制，显得不那么有效。但不管我多么努力去尝试，都没有找到这样的触发因素。所以我倾向于一个假设（这个假设到现在为止还没有被证伪），通过恰当地运用抽象能力，理解一个程序所需的脑力活动，最多只会与程序长度成正比增长。而这项观察的一个副产品，则具有更强大的现实意义，这也是第四个论据的基础。这个副产品就是在编程过程所展现出来的大量的抽象模式，它们在编程中扮演了关键角色。这些模式现在广为人知，所以你可以对它们中的每一个模式都举办一次讲座。当我清晰地意识到这些抽象模式的时候，我想到，如果 15 年前他们就广为人知，那从 BNF 到语法导向的编译器的发展，将只会花费几分钟，而不是好几年。所以我把近年来发现的关键抽象模式知识作为第四项论据。

    现在我们来阐述第五项论据。它与我们正在使用的工具有关，这些工具影响了我们自己的思维习惯。我观察到了一个文化传统，它根植于文艺复兴时期，这个传统倾向于忽视工具的影响，把人类思维作为至高无上的存在，并且认为人类是这些工具的掌管者。但是当我开始分析我自己以及同事们的思维习惯时，我发现了一个完全不同的结论，不管我是否喜欢这个结论：我们正在尝试使用的工具，还有我们正用于表达和记录思想的语言或标识符号，竟然在我们思考和表达内容方面起决定性作用！编程语言对它的使用者思维方式产生的影响，以及认识到脑力是目前为止我们最稀缺的资源，这给我们提供了不同编程语言相对优点对比的衡量标准。合格的程序员，能够意识到他的脑力是有限的，所以他在处理编程问题时，会非常谦卑，并且会像躲避瘟疫一样去避免使用一些投机取巧的小技巧。在广为人知的交互式编程语言环境下，我从各方面都听说，一旦编程环境有了一个终端，就会出现一个特别的现象，它还有一个一语双关的名字：单行程序。它会呈现出两种不同的形式：一个程序员把单行代码发到另外一个程序员的界面上，他要么会很骄傲地解释这行程序做了什么，随后提出一个问题“你可以写出再简洁一点的程序吗？”这就好像是在进行意识领域的讨论！或者他仅仅会问“猜猜这行程序做了什么？”从这个观察中，我们可以总结出，作为工具的语言，可以提供很多投机取巧的小技巧，对那些想展示他们有多聪明的程序员而言，编程语言呈现出强大的吸引力。但是我很遗憾，我必须说，这是一个程序语言最可恶的地方。从最近的经历，我们还可以学习到，编程语言越来越丰富，越来越强大的功能，从某种意义上来讲是犯下的一个错误，因为这些巴洛克式的复杂建筑，这些混搭的功能，真的很难管理，不管从机制上还是理解上。我能看到，在未来，编程语言将变得系统化和简洁。我说的“简洁”的意思是，例如，不仅是 ALGOL 60 的 for 从句，还有 FORTRAN 的 do 循环语句都会被认为是巴洛克式的复杂度。我设计过一次小的编程实验，参加者都是编程方面极其有经验的志愿者，但是结果出现了一些意想不到的事情。没有一个志愿者能找到显而易见和最优雅的解决方法。仔细分析一下，就会发现一个共同的原因：他们的想法被紧紧地绑定在了一个需要加速的变量上，这种思维定势阻挡了他们看到显而易见的方法。他们的解决方法更加低效，这就无谓地增加了理解的难度，并且他们花了很长时间才找到这些方法。这是一段发人深省、令人震撼的经历。最后，从某方面来讲，人们希望未来的编程语言，将极大地区别于我们现在所使用的：用这些编程语言写下的代码，应当能很好地应对软件设计的复杂性。这就是未来工具的优点，也是第五项论据的基础。

此外，我想要警告某些人，他们认为现在编程任务的困难是工具能力的不足所引起的，他们可能会得到一个结论，一旦我们的工具变得更好，编程就不再是一个问题。但是我想说，编程将仍然是困难的，因为一旦从复杂的工具环境中解脱出来，我们将需要面对超出我们现有编程能力的问题。

    你可以挑战我的第六项论据。因为还不太容易找到实验证据来支撑它，但这不会阻止我相信它的合理性。到现在为止，我还没有提及“层次体系“这个单词，但是可以公平地说，它是所有系统的关键概念，这些系统都包含了层次化的解决方案。我相信，我们解决问题的唯一方式，就是找到一个层次分得很好的解决方案。乍看起来，这一观点中的局限性，会让你感到沮丧。但相反的，我不这样认为！学习局限性的最好方法就是去了解它们。当我们谦卑到能够尝试层次化解决方案时（因为其他方法已经超出了我们的智力范围），我们就能够尽最大努力，以有效的方式给系统进行分层。而我们会发现，原本不能解决的问题居然能够被分解成若干小问题了。程序员发现，被称为“代码生成”的编译阶段所产生的大部分问题，都可以被分解成很多小问题，这些程序员能理解我所说的这一点。层次化解决方案的广泛应用，就是我的第六项也是最后一项论据，这为接下来的十几年内将可能发生的软件革命，带来了技术可行性。

总的来说，对我的考量赋予多少权重，我会把这个决定权留给你们自己，因为我太清楚，我不能强迫其他人来接受我的信念。就像每个重大的变革一样，它都会激起强烈的反抗，每个人都可以扪心自问，反对软件发展的保守力量将来自哪里。就我来看，这些保守力量不会出现在一些主流领域，甚至不会在计算机领域。相反，它们可能出现在教学机构，因为那些机构提供了训练课程；以及计算机使用者所在的一些保守组织里，他们认为自己以前写的程序太重要了，以至于他们觉得重写或者改进这些程序是不值得的。因此，我们很伤心地看到，在一些大学里，主要的计算机辅助工具的选取，是由一些已有且昂贵的应用决定的。在选取时，教学机构却忽视了一个问题：这些学生用户们，他们希望自己开发程序，但现在他们却不得不忍受这类教学工具的限制。高能物理学科，就经常用实验设备的昂贵价格向科学社区勒索。当然，这在技术上是完全不可行的，但是你需要一个强有力的论据来反驳他们。事实上，我们没法保证，哎，平均水平的程序员能够阻止这场变革的发生：因为还有其他程序员，他们的编程效率很高，平均水平的程序员将会被淘汰掉。

可能还会有来自政治方面的阻碍。即使我们知道如何训练未来的专业程序员，我们所在的社会也不一定允许我们这样做。教授一种方法，而不是传播知识，这带来的首要效果就是，继续提高已经具有一定能力的人的技能，这样会继续拉开人们智力上的差距。在我们的社会中，教育系统是建立同质化文化的一种工具，精英阶层被阻止进入最顶层社会，所以合格程序员的教育，可能在政治上是行不通的。

现在我们来总结。自动计算机已经陪伴我们度过了 1/4 个世纪。它们作为工具所展示的能力，已经为我们的社会带来了巨大的影响，但相较于将在未来带给我们史无前例的智力上的影响，这简直就是冰山一角。层次化系统，看起来有这样一种属性，在某一层上作为一个整体的实体，将可以在更低的层级被细分，细分模块将具有更多的细节。所以在层次化系统中，层级每降低一级，时间和空间的自然粒度也会有一个数量级的下降。我们通过砖头认识墙面，通过结晶体认识砖头，通过分子认识结晶体等等。所以，层次化系统中可以被有意义地区分开的层次数量，与最大和最小粒度之比呈对数正比。于是，除非这个粒度之比非常大，否则我们不会有太多层。在计算机编程中，基本的构建模块在时间维度上具有小于一微秒的粒度，但是我们的程序，可能要花费数小时的计算时间。我不知道是否还有其他什么技术，它的粒度之比是 10 的 10 次方或者更高：计算机以快速的计算能力见长，在计算机环境中，高度层次化的系统看起来是可能的也是必要的。编程任务带来的挑战是如此的独一无二，它可以教会我们很多东西，它会加深我们对设计和创造事物的理解，他会在我们思考时带来更好的控制力。

历史已经教给了我们一些训诫，而我在这个演讲中想强调的要点如下：我们应该在编程工作上做得更好，（实现这一目标的前提是）只要我们意识到，我们所面临的任务的巨大难度，只要我们坚持简洁而优雅的编程语言，只要我们对人类思维的内在局限性心存敬意，并且在解决程序问题时，成为一个谦卑的程序员。

* 英文版

ACM Turing Lecture 1972 	
EWD340

The Humble Programmer
by
Edsger W. Dijkstra

As a result of a long sequence of coincidences I entered the programming profession officially on the first spring morning of 1952 and as far as I have been able to trace, I was the first Dutchman to do so in my country. In retrospect the most amazing thing was the slowness with which, at least in my part of the world, the programming profession emerged, a slowness which is now hard to believe. But I am grateful for two vivid recollections from that period that establish that slowness beyond any doubt.

After having programmed for some three years, I had a discussion with A. van Wijngaarden, who was then my boss at the Mathematical Centre in Amsterdam, a discussion for which I shall remain grateful to him as long as I live. The point was that I was supposed to study theoretical physics at the University of Leiden simultaneously, and as I found the two activities harder and harder to combine, I had to make up my mind, either to stop programming and become a real, respectable theoretical physicist, or to carry my study of physics to a formal completion only, with a minimum of effort, and to become....., yes what? A programmer? But was that a respectable profession? For after all, what was programming? Where was the sound body of knowledge that could support it as an intellectually respectable discipline? I remember quite vividly how I envied my hardware colleagues, who, when asked about their professional competence, could at least point out that they knew everything about vacuum tubes, amplifiers and the rest, whereas I felt that, when faced with that question, I would stand empty-handed. Full of misgivings I knocked on van Wijngaarden’s office door, asking him whether I could “speak to him for a moment”; when I left his office a number of hours later, I was another person. For after having listened to my problems patiently, he agreed that up till that moment there was not much of a programming discipline, but then he went on to explain quietly that automatic computers were here to stay, that we were just at the beginning and could not I be one of the persons called to make programming a respectable discipline in the years to come? This was a turning point in my life and I completed my study of physics formally as quickly as I could. One moral of the above story is, of course, that we must be very careful when we give advice to younger people; sometimes they follow it!

Another two years later, in 1957, I married and Dutch marriage rites require you to state your profession and I stated that I was a programmer. But the municipal authorities of the town of Amsterdam did not accept it on the grounds that there was no such profession. And, believe it or not, but under the heading “profession” my marriage act shows the ridiculous entry “theoretical physicist”!

So much for the slowness with which I saw the programming profession emerge in my own country. Since then I have seen more of the world, and it is my general impression that in other countries, apart from a possible shift of dates, the growth pattern has been very much the same.

Let me try to capture the situation in those old days in a little bit more detail, in the hope of getting a better understanding of the situation today. While we pursue our analysis, we shall see how many common misunderstandings about the true nature of the programming task can be traced back to that now distant past.

The first automatic electronic computers were all unique, single-copy machines and they were all to be found in an environment with the exciting flavour of an experimental laboratory. Once the vision of the automatic computer was there, its realisation was a tremendous challenge to the electronic technology then available, and one thing is certain: we cannot deny the courage of the groups that decided to try and build such a fantastic piece of equipment. For fantastic pieces of equipment they were: in retrospect one can only wonder that those first machines worked at all, at least sometimes. The overwhelming problem was to get and keep the machine in working order. The preoccupation with the physical aspects of automatic computing is still reflected in the names of the older scientific societies in the field, such as the Association for Computing Machinery or the British Computer Society, names in which explicit reference is made to the physical equipment.

What about the poor programmer? Well, to tell the honest truth: he was hardly noticed. For one thing, the first machines were so bulky that you could hardly move them and besides that, they required such extensive maintenance that it was quite natural that the place where people tried to use the machine was the same laboratory where the machine had been developed. Secondly, his somewhat invisible work was without any glamour: you could show the machine to visitors and that was several orders of magnitude more spectacular than some sheets of coding. But most important of all, the programmer himself had a very modest view of his own work: his work derived all its significance from the existence of that wonderful machine. Because that was a unique machine, he knew only too well that his programs had only local significance and also, because it was patently obvious that this machine would have a limited lifetime, he knew that very little of his work would have a lasting value. Finally, there is yet another circumstance that had a profound influence on the programmer’s attitude to his work: on the one hand, besides being unreliable, his machine was usually too slow and its memory was usually too small, i.e. he was faced with a pinching shoe, while on the other hand its usually somewhat queer order code would cater for the most unexpected constructions. And in those days many a clever programmer derived an immense intellectual satisfaction from the cunning tricks by means of which he contrived to squeeze the impossible into the constraints of his equipment.

Two opinions about programming date from those days. I mention them now, I shall return to them later. The one opinion was that a really competent programmer should be puzzle-minded and very fond of clever tricks; the other opinion was that programming was nothing more than optimizing the efficiency of the computational process, in one direction or the other.

The latter opinion was the result of the frequent circumstance that, indeed, the available equipment was a painfully pinching shoe, and in those days one often encountered the naive expectation that, once more powerful machines were available, programming would no longer be a problem, for then the struggle to push the machine to its limits would no longer be necessary and that was all what programming was about, wasn’t it? But in the next decades something completely different happened: more powerful machines became available, not just an order of magnitude more powerful, even several orders of magnitude more powerful. But instead of finding ourselves in the state of eternal bliss of all programming problems solved, we found ourselves up to our necks in the software crisis! How come?

There is a minor cause: in one or two respects modern machinery is basically more difficult to handle than the old machinery. Firstly, we have got the I/O interrupts, occurring at unpredictable and irreproducible moments; compared with the old sequential machine that pretended to be a fully deterministic automaton, this has been a dramatic change and many a systems programmer’s grey hair bears witness to the fact that we should not talk lightly about the logical problems created by that feature. Secondly, we have got machines equipped with multi-level stores, presenting us problems of management strategy that, in spite of the extensive literature on the subject, still remain rather elusive. So much for the added complication due to structural changes of the actual machines.

But I called this a minor cause; the major cause is... that the machines have become several orders of magnitude more powerful! To put it quite bluntly: as long as there were no machines, programming was no problem at all; when we had a few weak computers, programming became a mild problem, and now we have gigantic computers, programming had become an equally gigantic problem. In this sense the electronic industry has not solved a single problem, it has only created them, it has created the problem of using its products. To put it in another way: as the power of available machines grew by a factor of more than a thousand, society’s ambition to apply these machines grew in proportion, and it was the poor programmer who found his job in this exploded field of tension between ends and means. The increased power of the hardware, together with the perhaps even more dramatic increase in its reliability, made solutions feasible that the programmer had not dared to dream about a few years before. And now, a few years later, he had to dream about them and, even worse, he had to transform such dreams into reality! Is it a wonder that we found ourselves in a software crisis? No, certainly not, and as you may guess, it was even predicted well in advance; but the trouble with minor prophets, of course, is that it is only five years later that you really know that they had been right.

Then, in the mid-sixties, something terrible happened: the computers of the so-called third generation made their appearance. The official literature tells us that their price/performance ratio has been one of the major design objectives. But if you take as “performance” the duty cycle of the machine’s various components, little will prevent you from ending up with a design in which the major part of your performance goal is reached by internal housekeeping activities of doubtful necessity. And if your definition of price is the price to be paid for the hardware, little will prevent you from ending up with a design that is terribly hard to program for: for instance the order code might be such as to enforce, either upon the programmer or upon the system, early binding decisions presenting conflicts that really cannot be resolved. And to a large extent these unpleasant possibilities seem to have become reality.

When these machines were announced and their functional specifications became known, quite a few among us must have become quite miserable; at least I was. It was only reasonable to expect that such machines would flood the computing community, and it was therefore all the more important that their design should be as sound as possible. But the design embodied such serious flaws that I felt that with a single stroke the progress of computing science had been retarded by at least ten years: it was then that I had the blackest week in the whole of my professional life. Perhaps the most saddening thing now is that, even after all those years of frustrating experience, still so many people honestly believe that some law of nature tells us that machines have to be that way. They silence their doubts by observing how many of these machines have been sold, and derive from that observation the false sense of security that, after all, the design cannot have been that bad. But upon closer inspection, that line of defense has the same convincing strength as the argument that cigarette smoking must be healthy because so many people do it.

It is in this connection that I regret that it is not customary for scientific journals in the computing area to publish reviews of newly announced computers in much the same way as we review scientific publications: to review machines would be at least as important. And here I have a confession to make: in the early sixties I wrote such a review with the intention of submitting it to the CACM, but in spite of the fact that the few colleagues to whom the text was sent for their advice, urged me all to do so, I did not dare to do it, fearing that the difficulties either for myself or for the editorial board would prove to be too great. This suppression was an act of cowardice on my side for which I blame myself more and more. The difficulties I foresaw were a consequence of the absence of generally accepted criteria, and although I was convinced of the validity of the criteria I had chosen to apply, I feared that my review would be refused or discarded as “a matter of personal taste”. I still think that such reviews would be extremely useful and I am longing to see them appear, for their accepted appearance would be a sure sign of maturity of the computing community.

The reason that I have paid the above attention to the hardware scene is because I have the feeling that one of the most important aspects of any computing tool is its influence on the thinking habits of those that try to use it, and because I have reasons to believe that that influence is many times stronger than is commonly assumed. Let us now switch our attention to the software scene.

Here the diversity has been so large that I must confine myself to a few stepping stones. I am painfully aware of the arbitrariness of my choice and I beg you not to draw any conclusions with regard to my appreciation of the many efforts that will remain unmentioned.

In the beginning there was the EDSAC in Cambridge, England, and I think it quite impressive that right from the start the notion of a subroutine library played a central role in the design of that machine and of the way in which it should be used. It is now nearly 25 years later and the computing scene has changed dramatically, but the notion of basic software is still with us, and the notion of the closed subroutine is still one of the key concepts in programming. We should recognise the closed subroutines as one of the greatest software inventions; it has survived three generations of computers and it will survive a few more, because it caters for the implementation of one of our basic patterns of abstraction. Regrettably enough, its importance has been underestimated in the design of the third generation computers, in which the great number of explicitly named registers of the arithmetic unit implies a large overhead on the subroutine mechanism. But even that did not kill the concept of the subroutine, and we can only pray that the mutation won’t prove to be hereditary.

The second major development on the software scene that I would like to mention is the birth of FORTRAN. At that time this was a project of great temerity and the people responsible for it deserve our great admiration. It would be absolutely unfair to blame them for shortcomings that only became apparent after a decade or so of extensive usage: groups with a successful look-ahead of ten years are quite rare! In retrospect we must rate FORTRAN as a successful coding technique, but with very few effective aids to conception, aids which are now so urgently needed that time has come to consider it out of date. The sooner we can forget that FORTRAN has ever existed, the better, for as a vehicle of thought it is no longer adequate: it wastes our brainpower, is too risky and therefore too expensive to use. FORTRAN’s tragic fate has been its wide acceptance, mentally chaining thousands and thousands of programmers to our past mistakes. I pray daily that more of my fellow-programmers may find the means of freeing themselves from the curse of compatibility.

The third project I would not like to leave unmentioned is LISP, a fascinating enterprise of a completely different nature. With a few very basic principles at its foundation, it has shown a remarkable stability. Besides that, LISP has been the carrier for a considerable number of in a sense our most sophisticated computer applications. LISP has jokingly been described as “the most intelligent way to misuse a computer”. I think that description a great compliment because it transmits the full flavour of liberation: it has assisted a number of our most gifted fellow humans in thinking previously impossible thoughts.

The fourth project to be mentioned is ALGOL 60. While up to the present day FORTRAN programmers still tend to understand their programming language in terms of the specific implementation they are working with —hence the prevalence of octal and hexadecimal dumps—, while the definition of LISP is still a curious mixture of what the language means and how the mechanism works, the famous Report on the Algorithmic Language ALGOL 60 is the fruit of a genuine effort to carry abstraction a vital step further and to define a programming language in an implementation-independent way. One could argue that in this respect its authors have been so successful that they have created serious doubts as to whether it could be implemented at all! The report gloriously demonstrated the power of the formal method BNF, now fairly known as Backus-Naur-Form, and the power of carefully phrased English, a least when used by someone as brilliant as Peter Naur. I think that it is fair to say that only very few documents as short as this have had an equally profound influence on the computing community. The ease with which in later years the names ALGOL and ALGOL-like have been used, as an unprotected trade mark, to lend some of its glory to a number of sometimes hardly related younger projects, is a somewhat shocking compliment to its standing. The strength of BNF as a defining device is responsible for what I regard as one of the weaknesses of the language: an over-elaborate and not too systematic syntax could now be crammed into the confines of very few pages. With a device as powerful as BNF, the Report on the Algorithmic Language ALGOL 60 should have been much shorter. Besides that I am getting very doubtful about ALGOL 60’s parameter mechanism: it allows the programmer so much combinatorial freedom, that its confident use requires a strong discipline from the programmer. Besides expensive to implement it seems dangerous to use.

Finally, although the subject is not a pleasant one, I must mention PL/1, a programming language for which the defining documentation is of a frightening size and complexity. Using PL/1 must be like flying a plane with 7000 buttons, switches and handles to manipulate in the cockpit. I absolutely fail to see how we can keep our growing programs firmly within our intellectual grip when by its sheer baroqueness the programming language —our basic tool, mind you!— already escapes our intellectual control. And if I have to describe the influence PL/1 can have on its users, the closest metaphor that comes to my mind is that of a drug. I remember from a symposium on higher level programming language a lecture given in defense of PL/1 by a man who described himself as one of its devoted users. But within a one-hour lecture in praise of PL/1. he managed to ask for the addition of about fifty new “features”, little supposing that the main source of his problems could very well be that it contained already far too many “features”. The speaker displayed all the depressing symptoms of addiction, reduced as he was to the state of mental stagnation in which he could only ask for more, more, more... When FORTRAN has been called an infantile disorder, full PL/1, with its growth characteristics of a dangerous tumor, could turn out to be a fatal disease.

So much for the past. But there is no point in making mistakes unless thereafter we are able to learn from them. As a matter of fact, I think that we have learned so much, that within a few years programming can be an activity vastly different from what it has been up till now, so different that we had better prepare ourselves for the shock. Let me sketch for you one of the possible futures. At first sight, this vision of programming in perhaps already the near future may strike you as utterly fantastic. Let me therefore also add the considerations that might lead one to the conclusion that this vision could be a very real possibility.

The vision is that, well before the seventies have run to completion, we shall be able to design and implement the kind of systems that are now straining our programming ability, at the expense of only a few percent in man-years of what they cost us now, and that besides that, these systems will be virtually free of bugs. These two improvements go hand in hand. In the latter respect software seems to be different from many other products, where as a rule a higher quality implies a higher price. Those who want really reliable software will discover that they must find means of avoiding the majority of bugs to start with, and as a result the programming process will become cheaper. If you want more effective programmers, you will discover that they should not waste their time debugging, they should not introduce the bugs to start with. In other words: both goals point to the same change.

Such a drastic change in such a short period of time would be a revolution, and to all persons that base their expectations for the future on smooth extrapolation of the recent past —appealing to some unwritten laws of social and cultural inertia— the chance that this drastic change will take place must seem negligible. But we all know that sometimes revolutions do take place! And what are the chances for this one?

There seem to be three major conditions that must be fulfilled. The world at large must recognize the need for the change; secondly the economic need for it must be sufficiently strong; and, thirdly, the change must be technically feasible. Let me discuss these three conditions in the above order.

With respect to the recognition of the need for greater reliability of software, I expect no disagreement anymore. Only a few years ago this was different: to talk about a software crisis was blasphemy. The turning point was the Conference on Software Engineering in Garmisch, October 1968, a conference that created a sensation as there occurred the first open admission of the software crisis. And by now it is generally recognized that the design of any large sophisticated system is going to be a very difficult job, and whenever one meets people responsible for such undertakings, one finds them very much concerned about the reliability issue, and rightly so. In short, our first condition seems to be satisfied.

Now for the economic need. Nowadays one often encounters the opinion that in the sixties programming has been an overpaid profession, and that in the coming years programmer salaries may be expected to go down. Usually this opinion is expressed in connection with the recession, but it could be a symptom of something different and quite healthy, viz. that perhaps the programmers of the past decade have not done so good a job as they should have done. Society is getting dissatisfied with the performance of programmers and of their products. But there is another factor of much greater weight. In the present situation it is quite usual that for a specific system, the price to be paid for the development of the software is of the same order of magnitude as the price of the hardware needed, and society more or less accepts that. But hardware manufacturers tell us that in the next decade hardware prices can be expected to drop with a factor of ten. If software development were to continue to be the same clumsy and expensive process as it is now, things would get completely out of balance. You cannot expect society to accept this, and therefore we must learn to program an order of magnitude more effectively. To put it in another way: as long as machines were the largest item on the budget, the programming profession could get away with its clumsy techniques, but that umbrella will fold rapidly. In short, also our second condition seems to be satisfied.

And now the third condition: is it technically feasible? I think it might and I shall give you six arguments in support of that opinion.

A study of program structure had revealed that programs —even alternative programs for the same task and with the same mathematical content— can differ tremendously in their intellectual manageability. A number of rules have been discovered, violation of which will either seriously impair or totally destroy the intellectual manageability of the program. These rules are of two kinds. Those of the first kind are easily imposed mechanically, viz. by a suitably chosen programming language. Examples are the exclusion of goto-statements and of procedures with more than one output parameter. For those of the second kind I at least —but that may be due to lack of competence on my side— see no way of imposing them mechanically, as it seems to need some sort of automatic theorem prover for which I have no existence proof. Therefore, for the time being and perhaps forever, the rules of the second kind present themselves as elements of discipline required from the programmer. Some of the rules I have in mind are so clear that they can be taught and that there never needs to be an argument as to whether a given program violates them or not. Examples are the requirements that no loop should be written down without providing a proof for termination nor without stating the relation whose invariance will not be destroyed by the execution of the repeatable statement.

I now suggest that we confine ourselves to the design and implementation of intellectually manageable programs. If someone fears that this restriction is so severe that we cannot live with it, I can reassure him: the class of intellectually manageable programs is still sufficiently rich to contain many very realistic programs for any problem capable of algorithmic solution. We must not forget that it is not our business to make programs, it is our business to design classes of computations that will display a desired behaviour. The suggestion of confining ourselves to intellectually manageable programs is the basis for the first two of my announced six arguments.

Argument one is that, as the programmer only needs to consider intellectually manageable programs, the alternatives he is choosing between are much, much easier to cope with.

Argument two is that, as soon as we have decided to restrict ourselves to the subset of the intellectually manageable programs, we have achieved, once and for all, a drastic reduction of the solution space to be considered. And this argument is distinct from argument one.

Argument three is based on the constructive approach to the problem of program correctness. Today a usual technique is to make a program and then to test it. But: program testing can be a very effective way to show the presence of bugs, but is hopelessly inadequate for showing their absence. The only effective way to raise the confidence level of a program significantly is to give a convincing proof of its correctness. But one should not first make the program and then prove its correctness, because then the requirement of providing the proof would only increase the poor programmer’s burden. On the contrary: the programmer should let correctness proof and program grow hand in hand. Argument three is essentially based on the following observation. If one first asks oneself what the structure of a convincing proof would be and, having found this, then constructs a program satisfying this proof’s requirements, then these correctness concerns turn out to be a very effective heuristic guidance. By definition this approach is only applicable when we restrict ourselves to intellectually manageable programs, but it provides us with effective means for finding a satisfactory one among these.

Argument four has to do with the way in which the amount of intellectual effort needed to design a program depends on the program length. It has been suggested that there is some kind of law of nature telling us that the amount of intellectual effort needed grows with the square of program length. But, thank goodness, no one has been able to prove this law. And this is because it need not be true. We all know that the only mental tool by means of which a very finite piece of reasoning can cover a myriad cases is called “abstraction”; as a result the effective exploitation of his powers of abstraction must be regarded as one of the most vital activities of a competent programmer. In this connection it might be worth-while to point out that the purpose of abstracting is not to be vague, but to create a new semantic level in which one can be absolutely precise. Of course I have tried to find a fundamental cause that would prevent our abstraction mechanisms from being sufficiently effective. But no matter how hard I tried, I did not find such a cause. As a result I tend to the assumption —up till now not disproved by experience— that by suitable application of our powers of abstraction, the intellectual effort needed to conceive or to understand a program need not grow more than proportional to program length. But a by-product of these investigations may be of much greater practical significance, and is, in fact, the basis of my fourth argument. The by-product was the identification of a number of patterns of abstraction that play a vital role in the whole process of composing programs. Enough is now known about these patterns of abstraction that you could devote a lecture to about each of them. What the familiarity and conscious knowledge of these patterns of abstraction imply dawned upon me when I realized that, had they been common knowledge fifteen years ago, the step from BNF to syntax-directed compilers, for instance, could have taken a few minutes instead of a few years. Therefore I present our recent knowledge of vital abstraction patterns as the fourth argument.

Now for the fifth argument. It has to do with the influence of the tool we are trying to use upon our own thinking habits. I observe a cultural tradition, which in all probability has its roots in the Renaissance, to ignore this influence, to regard the human mind as the supreme and autonomous master of its artefacts. But if I start to analyse the thinking habits of myself and of my fellow human beings, I come, whether I like it or not, to a completely different conclusion, viz. that the tools we are trying to use and the language or notation we are using to express or record our thoughts, are the major factors determining what we can think or express at all! The analysis of the influence that programming languages have on the thinking habits of its users, and the recognition that, by now, brainpower is by far our scarcest resource, they together give us a new collection of yardsticks for comparing the relative merits of various programming languages. The competent programmer is fully aware of the strictly limited size of his own skull; therefore he approaches the programming task in full humility, and among other things he avoids clever tricks like the plague. In the case of a well-known conversational programming language I have been told from various sides that as soon as a programming community is equipped with a terminal for it, a specific phenomenon occurs that even has a well-established name: it is called “the one-liners”. It takes one of two different forms: one programmer places a one-line program on the desk of another and either he proudly tells what it does and adds the question “Can you code this in less symbols?” —as if this were of any conceptual relevance!— or he just asks “Guess what it does!”. From this observation we must conclude that this language as a tool is an open invitation for clever tricks; and while exactly this may be the explanation for some of its appeal, viz. to those who like to show how clever they are, I am sorry, but I must regard this as one of the most damning things that can be said about a programming language. Another lesson we should have learned from the recent past is that the development of “richer” or “more powerful” programming languages was a mistake in the sense that these baroque monstrosities, these conglomerations of idiosyncrasies, are really unmanageable, both mechanically and mentally. I see a great future for very systematic and very modest programming languages. When I say “modest”, I mean that, for instance, not only ALGOL 60’s “for clause”, but even FORTRAN’s “DO loop” may find themselves thrown out as being too baroque. I have run a a little programming experiment with really experienced volunteers, but something quite unintended and quite unexpected turned up. None of my volunteers found the obvious and most elegant solution. Upon closer analysis this turned out to have a common source: their notion of repetition was so tightly connected to the idea of an associated controlled variable to be stepped up, that they were mentally blocked from seeing the obvious. Their solutions were less efficient, needlessly hard to understand, and it took them a very long time to find them. It was a revealing, but also shocking experience for me. Finally, in one respect one hopes that tomorrow’s programming languages will differ greatly from what we are used to now: to a much greater extent than hitherto they should invite us to reflect in the structure of what we write down all abstractions needed to cope conceptually with the complexity of what we are designing. So much for the greater adequacy of our future tools, which was the basis of the fifth argument.

As an aside I would like to insert a warning to those who identify the difficulty of the programming task with the struggle against the inadequacies of our current tools, because they might conclude that, once our tools will be much more adequate, programming will no longer be a problem. Programming will remain very difficult, because once we have freed ourselves from the circumstantial cumbersomeness, we will find ourselves free to tackle the problems that are now well beyond our programming capacity.

You can quarrel with my sixth argument, for it is not so easy to collect experimental evidence for its support, a fact that will not prevent me from believing in its validity. Up till now I have not mentioned the word “hierarchy”, but I think that it is fair to say that this is a key concept for all systems embodying a nicely factored solution. I could even go one step further and make an article of faith out of it, viz. that the only problems we can really solve in a satisfactory manner are those that finally admit a nicely factored solution. At first sight this view of human limitations may strike you as a rather depressing view of our predicament, but I don’t feel it that way, on the contrary! The best way to learn to live with our limitations is to know them. By the time that we are sufficiently modest to try factored solutions only, because the other efforts escape our intellectual grip, we shall do our utmost best to avoid all those interfaces impairing our ability to factor the system in a helpful way. And I cannot but expect that this will repeatedly lead to the discovery that an initially untractable problem can be factored after all. Anyone who has seen how the majority of the troubles of the compiling phase called “code generation” can be tracked down to funny properties of the order code, will know a simple example of the kind of things I have in mind. The wider applicability of nicely factored solutions is my sixth and last argument for the technical feasibility of the revolution that might take place in the current decade.

In principle I leave it to you to decide for yourself how much weight you are going to give to my considerations, knowing only too well that I can force no one else to share my beliefs. As each serious revolution, it will provoke violent opposition and one can ask oneself where to expect the conservative forces trying to counteract such a development. I don’t expect them primarily in big business, not even in the computer business; I expect them rather in the educational institutions that provide today’s training and in those conservative groups of computer users that think their old programs so important that they don’t think it worth-while to rewrite and improve them. In this connection it is sad to observe that on many a university campus the choice of the central computing facility has too often been determined by the demands of a few established but expensive applications with a disregard of the question how many thousands of “small users” that are willing to write their own programs were going to suffer from this choice. Too often, for instance, high-energy physics seems to have blackmailed the scientific community with the price of its remaining experimental equipment. The easiest answer, of course, is a flat denial of the technical feasibility, but I am afraid that you need pretty strong arguments for that. No reassurance, alas, can be obtained from the remark that the intellectual ceiling of today’s average programmer will prevent the revolution from taking place: with others programming so much more effectively, he is liable to be edged out of the picture anyway.

There may also be political impediments. Even if we know how to educate tomorrow’s professional programmer, it is not certain that the society we are living in will allow us to do so. The first effect of teaching a methodology —rather than disseminating knowledge— is that of enhancing the capacities of the already capable, thus magnifying the difference in intelligence. In a society in which the educational system is used as an instrument for the establishment of a homogenized culture, in which the cream is prevented from rising to the top, the education of competent programmers could be politically impalatable.

Let me conclude. Automatic computers have now been with us for a quarter of a century. They have had a great impact on our society in their capacity of tools, but in that capacity their influence will be but a ripple on the surface of our culture, compared with the much more profound influence they will have in their capacity of intellectual challenge without precedent in the cultural history of mankind. Hierarchical systems seem to have the property that something considered as an undivided entity on one level, is considered as a composite object on the next lower level of greater detail; as a result the natural grain of space or time that is applicable at each level decreases by an order of magnitude when we shift our attention from one level to the next lower one. We understand walls in terms of bricks, bricks in terms of crystals, crystals in terms of molecules etc. As a result the number of levels that can be distinguished meaningfully in a hierarchical system is kind of proportional to the logarithm of the ratio between the largest and the smallest grain, and therefore, unless this ratio is very large, we cannot expect many levels. In computer programming our basic building block has an associated time grain of less than a microsecond, but our program may take hours of computation time. I do not know of any other technology covering a ratio of 1010 or more: the computer, by virtue of its fantastic speed, seems to be the first to provide us with an environment where highly hierarchical artefacts are both possible and necessary. This challenge, viz. the confrontation with the programming task, is so unique that this novel experience can teach us a lot about ourselves. It should deepen our understanding of the processes of design and creation, it should give us better control over the task of organizing our thoughts. If it did not do so, to my taste we should not deserve the computer at all!

It has already taught us a few lessons, and the one I have chosen to stress in this talk is the following. We shall do a much better programming job, provided that we approach the task with a full appreciation of its tremendous difficulty, provided that we stick to modest and elegant programming languages, provided that we respect the intrinsic limitations of the human mind and approach the task as Very Humble Programmers.

transcribed by
revised 05-Feb-2013
